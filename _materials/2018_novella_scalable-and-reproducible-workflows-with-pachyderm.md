---
layout: material
title: Scalable and reproducible workflows with Pachyderm
description: |-
  Data scientists must manage analyses that consist of multiple stages, large datasets and a great number of tools, all the while maintaining reproducibility of results. Amongst the variety of available tools to undertake parallel computations, Pachyderm is an open-source workflow-engine and distributed data processing tool that fulfils these needs by creating a data pipelining and data versioning layer on top of projects from the container ecosystem. In this workshop you will learn how to:

  * create a simple local Kubernetes infrastructure,
  * install and interact with Pachyderm and
  * implement a scalable and reproducible workflow using containers.
author: 
  - 
    name: Jon Ander Novella
    institution: Uppsala Universitet
domain: Generic/ cross-domain
topic: 
keywords: 
  - pachyderm
  - workflow management
time_required: 5 hours
target role: 
language: English
date_created: 06.08.2016
date_modified: 28.08.2018
type: Hands-on exercises
license: ""
version: ""
pid: ""
skills: 
  - 
    name: Plan stewardship and sharing of FAIR outputs
    level: basic
  - 
    name: Set up and document workflows
    level: intermediate
  - 
    name: Data cleaning, processing and software versioning
    level: intermediate
  - 
    name: Data transformation and integration
    level: basic
  - 
    name: Prepare and document for FAIR outputs
    level: intermediate
  - 
    name: Workflow set-up and provenance information mgmt
    level: basic
external_url: https://indico.scc.kit.edu/event/427/contributions/4248/
reference: https://doi.org/10.1093/bioinformatics/bty699
provider: GridKa School 2018
---
